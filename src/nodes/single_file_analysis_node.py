"""
SingleFileAnalysisNode - å•æ–‡ä»¶ä»£ç åˆ†æèŠ‚ç‚¹
åŸºäº WebCodeAnalysisNode å’Œ CodeParsingBatchNode çš„é€»è¾‘ï¼Œä¸“é—¨ç”¨äºåˆ†æå•ä¸ªæ–‡ä»¶
"""

import aiohttp
from typing import Dict, Any, List
from pocketflow import AsyncNode

from ..utils.llm_parser import LLMParser
from ..utils.rag_api_client import RAGAPIClient
from ..utils.logger import logger
from ..utils.error_handler import LLMParsingError
from ..utils.config import get_config


class SingleFileAnalysisNode(AsyncNode):
    """å•æ–‡ä»¶ä»£ç åˆ†æèŠ‚ç‚¹"""

    def __init__(self):
        super().__init__()
        self.llm_parser = LLMParser()  # LLMè§£æå™¨

        config = get_config()
        self.rag_client = RAGAPIClient(config.rag_base_url)  # RAG APIå®¢æˆ·ç«¯
        self.api_base_url = config.api_base_url  # åç«¯APIåœ°å€

    async def exec_async(self, shared: Dict[str, Any]) -> str:
        """
        åˆ†æå•ä¸ªæ–‡ä»¶ï¼šè·å–ä»£ç å†…å®¹ -> RAGæ£€ç´¢ -> LLMåˆ†æ

        Data Access:
        - Read: shared.file_id, shared.vectorstore_index
        - Write: shared.single_file_analysis
        """
        logger.info("=" * 60)
        logger.info("ğŸ“‹ é˜¶æ®µ: å•æ–‡ä»¶ä»£ç åˆ†æ (SingleFileAnalysisNode)")

        shared["current_stage"] = "single_file_analysis"

        file_id = shared.get("file_id")
        vectorstore_index = shared.get("vectorstore_index")

        if not file_id:
            logger.error("âŒ å•æ–‡ä»¶åˆ†æéœ€è¦æä¾›æ–‡ä»¶ID")
            raise LLMParsingError("File ID is required")

        if not vectorstore_index:
            logger.error("âŒ å•æ–‡ä»¶åˆ†æéœ€è¦æä¾›å‘é‡ç´¢å¼•")
            raise LLMParsingError("Vectorstore index is required")

        try:
            # 1. è·å–æ–‡ä»¶ä¿¡æ¯å’Œå†…å®¹
            file_info = await self._get_file_info(file_id)
            if not file_info:
                logger.error(f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: file_id={file_id}")
                shared["single_file_analysis"] = []
                shared["status"] = "failed"
                shared["error"] = "æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯"
                return "default"

            file_path = file_info.get("file_path", "")
            language = file_info.get("language", "unknown")
            content = file_info.get("code_content", "")

            if not content:
                logger.warning(f"æ–‡ä»¶å†…å®¹ä¸ºç©º: {file_path}")
                shared["single_file_analysis"] = []
                shared["status"] = "completed"
                return "default"

            logger.info(f"ğŸ” å¼€å§‹åˆ†ææ–‡ä»¶: {file_path} (ID: {file_id})")

            # 2. ä½¿ç”¨RAGè·å–ç›¸å…³ä¸Šä¸‹æ–‡
            context = await self._get_rag_context(file_path, content, language, vectorstore_index)

            # 3. è°ƒç”¨LLMè¿›è¡Œè¯¦ç»†åˆ†æ
            result = await self.llm_parser.parse_code_file_detailed(file_path, content, language, context)

            # 4. å¤„ç†åˆ†æç»“æœ
            if not result.get("error"):
                result["file_id"] = file_id
                # ä¸ºæ¯ä¸ªåˆ†æé¡¹æ·»åŠ file_id
                for item in result.get("analysis_items", []):
                    item["file_id"] = file_id

                shared["single_file_analysis"] = [result]
                shared["status"] = "completed"
                logger.info(f"âœ… å®Œæˆæ–‡ä»¶åˆ†æ: {file_path}")
            else:
                logger.error(f"âŒ æ–‡ä»¶åˆ†æå¤±è´¥: {file_path}, é”™è¯¯: {result.get('error')}")
                shared["single_file_analysis"] = []
                shared["status"] = "failed"
                shared["error"] = result.get("error")

            return "default"

        except Exception as e:
            logger.error(f"âŒ å•æ–‡ä»¶åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            shared["single_file_analysis"] = []
            shared["status"] = "failed"
            shared["error"] = str(e)
            return "default"

    async def _get_file_info(self, file_id: int) -> Dict[str, Any]:
        """ä»APIè·å–æ–‡ä»¶ä¿¡æ¯å’Œå†…å®¹"""
        try:
            # é¦–å…ˆè·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            url = f"{self.api_base_url}/api/repository/file-analysis/{file_id}"

            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get("status") == "success":
                            return data.get("file_analysis", {})
                    else:
                        logger.error(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: HTTP {response.status}")
                        return {}

        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {}

    async def _get_rag_context(self, file_path: str, content: str, language: str, vectorstore_index: str) -> str:
        """
        ä½¿ç”¨RAG APIè·å–ä¸å½“å‰æ–‡ä»¶ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        å¤ç”¨WebCodeAnalysisNodeçš„RAGé€»è¾‘
        """
        try:
            if not vectorstore_index:
                logger.warning("RAG API ç´¢å¼•ä¸å¯ç”¨")
                return ""

            # 1. æå–ç±»-æ–¹æ³•å…³è”å…³ç³»å’Œç‹¬ç«‹å‡½æ•°
            class_method_relationships = self._extract_class_method_relationships(content, language)
            independent_functions = self._extract_independent_functions(content, language, class_method_relationships)

            logger.info(f"ğŸ” ä» {file_path} æ–‡ä»¶ä¸­æå–åˆ°:")
            logger.info(f"   - ç±»: {list(class_method_relationships.keys())}")
            logger.info(f"   - ç‹¬ç«‹å‡½æ•°: {independent_functions}")

            # 2. æ„å»ºæ£€ç´¢ç­–ç•¥ï¼šæ–‡ä»¶ + æ¯ä¸ªç±» + æ¯ä¸ªç‹¬ç«‹å‡½æ•°
            search_queries = []
            search_targets = []

            # 2.1 å¯¹æ–‡ä»¶æœ¬èº«è¿›è¡Œæ£€ç´¢
            search_queries.append(f"{file_path} {language} æ–‡ä»¶")
            search_targets.append(f"æ–‡ä»¶-{file_path}")

            # 2.2 å¯¹æ¯ä¸ªç±»è¿›è¡Œæ£€ç´¢
            for class_name, methods in class_method_relationships.items():
                search_queries.append(f"{file_path} {class_name} ç±» {language}")
                search_targets.append(f"æ–‡ä»¶-ç±»({class_name})")

            # 2.3 å¯¹æ¯ä¸ªç‹¬ç«‹å‡½æ•°è¿›è¡Œæ£€ç´¢
            for func_name in independent_functions:
                search_queries.append(f"{file_path} {func_name} å‡½æ•° {language}")
                search_targets.append(f"æ–‡ä»¶-å‡½æ•°({func_name})")

            # 3. æ‰§è¡Œæ£€ç´¢
            all_results = []
            total_searches = len(search_queries)

            for i, (query, target) in enumerate(zip(search_queries, search_targets)):
                try:
                    logger.info(f"   [{i+1}/{total_searches}] æ£€ç´¢: {target}")

                    search_results = await self.rag_client.search(
                        query=query, index_name=vectorstore_index, top_k=3, score_threshold=0.3
                    )

                    if search_results and search_results.get("results"):
                        for result in search_results["results"]:
                            result["search_target"] = target
                            all_results.append(result)

                        logger.info(f"   [{i+1}/{total_searches}] âœ… æ‰¾åˆ° {len(search_results['results'])} ä¸ªç›¸å…³ç»“æœ")
                    else:
                        logger.info(f"   [{i+1}/{total_searches}] âš ï¸ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")

                except Exception as e:
                    logger.warning(f"   [{i+1}/{total_searches}] æ£€ç´¢å¤±è´¥ {target}: {str(e)}")
                    continue

            # 4. ç®€å•å»é‡å¹¶ç»„åˆç»“æœ
            seen_content = set()
            unique_results = []
            for result in all_results:
                content_hash = hash(result["content"])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    unique_results.append(result)

            # 5. ç»„åˆæ£€ç´¢ç»“æœ
            if unique_results:
                context_parts = ["=== RAG æ£€ç´¢ä¸Šä¸‹æ–‡ ==="]

                # æŒ‰æ£€ç´¢ç›®æ ‡åˆ†ç»„
                target_groups = {}
                for result in unique_results[:15]:  # é™åˆ¶æœ€å¤š15ä¸ªç»“æœ
                    target = result.get("search_target", "æœªçŸ¥ç›®æ ‡")
                    if target not in target_groups:
                        target_groups[target] = []
                    target_groups[target].append(result)

                # æŒ‰ç›®æ ‡ç»„ç»‡è¾“å‡º
                for target, results in target_groups.items():
                    context_parts.append(f"\n--- {target} ---")
                    for result in results:
                        title = result.get("title", "æ— æ ‡é¢˜")
                        content = result.get("content", "")[:500]  # é™åˆ¶é•¿åº¦
                        context_parts.append(f"æ ‡é¢˜: {title}")
                        context_parts.append(f"å†…å®¹: {content}")
                        context_parts.append("")

                context = "\n".join(context_parts)
                logger.info(f"âœ… ä¸º {file_path} æ£€ç´¢åˆ° {len(unique_results)} ä¸ªç›¸å…³ä¸Šä¸‹æ–‡")
                return context
            else:
                logger.info(f"âš ï¸ æœªæ‰¾åˆ° {file_path} çš„ç›¸å…³ä¸Šä¸‹æ–‡")
                return ""

        except Exception as e:
            logger.warning(f"Failed to get RAG context for {file_path}: {str(e)}")
            return ""

    def _extract_class_method_relationships(self, content: str, language: str) -> Dict[str, List[str]]:
        """æå–ç±»å’Œæ–¹æ³•çš„å…³è”å…³ç³»"""
        import re
        import ast

        relationships = {}

        if language == "python":
            try:
                tree = ast.parse(content)

                for node in ast.walk(tree):
                    if isinstance(node, ast.ClassDef):
                        class_name = node.name
                        methods = []

                        # æå–ç±»ä¸­çš„æ–¹æ³•
                        for item in node.body:
                            if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                                methods.append(item.name)

                        relationships[class_name] = methods

            except Exception as e:
                logger.warning(f"Failed to parse AST: {e}")
                # å›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼
                return self._extract_class_method_relationships_regex(content)
        else:
            # å¯¹äºé Python è¯­è¨€ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
            return self._extract_class_method_relationships_regex(content)

        return relationships

    def _extract_class_method_relationships_regex(self, content: str) -> Dict[str, List[str]]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç±»å’Œæ–¹æ³•çš„å…³è”å…³ç³»"""
        import re

        relationships = {}
        lines = content.split("\n")
        current_class = None
        indent_level = 0

        for line in lines:
            stripped_line = line.strip()
            if not stripped_line:
                continue

            # è®¡ç®—ç¼©è¿›çº§åˆ«
            line_indent = len(line) - len(line.lstrip())

            # æ£€æµ‹ç±»å®šä¹‰
            class_match = re.match(r"^class\s+([A-Za-z_][A-Za-z0-9_]*)", stripped_line)
            if class_match:
                current_class = class_match.group(1)
                relationships[current_class] = []
                indent_level = line_indent
                continue

            # æ£€æµ‹æ–¹æ³•å®šä¹‰ï¼ˆåœ¨ç±»å†…éƒ¨ï¼‰
            if current_class and line_indent > indent_level:
                method_match = re.match(r"^(async\s+)?def\s+([A-Za-z_][A-Za-z0-9_]*)", stripped_line)
                if method_match:
                    method_name = method_match.group(2)
                    # è¿‡æ»¤æ‰ä¸€äº›æ— æ„ä¹‰çš„æ–¹æ³•å
                    if method_name not in {"__str__", "__repr__", "__eq__", "__hash__"}:
                        relationships[current_class].append(method_name)
            elif current_class and line_indent <= indent_level:
                # é€€å‡ºå½“å‰ç±»
                current_class = None

        return relationships

    def _extract_independent_functions(
        self, content: str, language: str, class_relationships: Dict[str, List[str]]
    ) -> List[str]:
        """æå–ç‹¬ç«‹å‡½æ•°ï¼ˆä¸åœ¨ç±»ä¸­çš„å‡½æ•°ï¼‰"""
        import re
        import ast

        independent_functions = []

        if language == "python":
            try:
                tree = ast.parse(content)

                # æ”¶é›†æ‰€æœ‰ç±»ä¸­çš„æ–¹æ³•å
                class_methods = set()
                for methods in class_relationships.values():
                    class_methods.update(methods)

                # æŸ¥æ‰¾æ¨¡å—çº§åˆ«çš„å‡½æ•°ï¼ˆä¸åœ¨ç±»ä¸­çš„å‡½æ•°ï¼‰
                for node in ast.walk(tree):
                    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        # æ£€æŸ¥å‡½æ•°æ˜¯å¦åœ¨æ¨¡å—çº§åˆ«ï¼ˆä¸åœ¨ç±»ä¸­ï¼‰
                        parent = getattr(node, "parent", None)
                        if parent is None or not isinstance(parent, ast.ClassDef):
                            # è¿™æ˜¯ä¸€ä¸ªæ¨¡å—çº§åˆ«çš„å‡½æ•°
                            func_name = node.name
                            if func_name not in class_methods and not func_name.startswith("_"):
                                independent_functions.append(func_name)

                # å¦‚æœASTè§£ææ²¡æœ‰parentä¿¡æ¯ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                if not independent_functions:
                    return self._extract_independent_functions_regex(content, class_relationships)

            except Exception as e:
                logger.warning(f"Failed to parse AST for functions: {e}")
                # å›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼
                return self._extract_independent_functions_regex(content, class_relationships)
        else:
            # å¯¹äºé Python è¯­è¨€ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
            return self._extract_independent_functions_regex(content, class_relationships)

        return independent_functions

    def _extract_independent_functions_regex(
        self, content: str, class_relationships: Dict[str, List[str]]
    ) -> List[str]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç‹¬ç«‹å‡½æ•°"""
        import re

        independent_functions = []
        lines = content.split("\n")

        # æ”¶é›†æ‰€æœ‰ç±»ä¸­çš„æ–¹æ³•å
        class_methods = set()
        for methods in class_relationships.values():
            class_methods.update(methods)

        # æŸ¥æ‰¾å‡½æ•°å®šä¹‰ï¼Œæ’é™¤ç±»ä¸­çš„æ–¹æ³•
        in_class = False
        class_indent = 0

        for line in lines:
            stripped_line = line.strip()
            if not stripped_line:
                continue

            line_indent = len(line) - len(line.lstrip())

            # æ£€æµ‹ç±»å®šä¹‰
            if re.match(r"^class\s+", stripped_line):
                in_class = True
                class_indent = line_indent
                continue

            # æ£€æŸ¥æ˜¯å¦é€€å‡ºç±»
            if in_class and line_indent <= class_indent and stripped_line and not stripped_line.startswith("#"):
                if not re.match(r"^(def|async\s+def|@)", stripped_line):
                    in_class = False

            # æŸ¥æ‰¾å‡½æ•°å®šä¹‰
            func_match = re.match(r"^(async\s+)?def\s+([A-Za-z_][A-Za-z0-9_]*)", stripped_line)
            if func_match and not in_class:
                func_name = func_match.group(2)
                if func_name not in class_methods and not func_name.startswith("_"):
                    independent_functions.append(func_name)

        return independent_functions
