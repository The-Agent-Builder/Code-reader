"""
READMEåˆ†æå’Œç”ŸæˆèŠ‚ç‚¹ - å¯¹GitHubä»“åº“çš„READMEè¿›è¡Œæ·±åº¦åˆ†æå’Œå®Œå–„
Design: AsyncNode, max_retries=2, wait=20
"""

from typing import Dict, Any, Optional, List
from pathlib import Path
from pocketflow import AsyncNode

from ..utils.llm_parser import LLMParser
from ..utils.rag_api_client import RAGAPIClient
from ..utils.logger import logger
from ..utils.error_handler import LLMParsingError
from ..utils.config import get_config


class ReadmeAnalysisNode(AsyncNode):
    """READMEåˆ†æå’Œç”ŸæˆèŠ‚ç‚¹"""

    def __init__(self):
        super().__init__(max_retries=2, wait=20)
        self.llm_parser = LLMParser()
        config = get_config()
        self.rag_client = RAGAPIClient(config.rag_base_url)

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‡†å¤‡READMEåˆ†ææ‰€éœ€çš„æ•°æ®

        Data Access:
        - Read: shared.local_path, shared.repo_info, shared.code_analysis, shared.vectorstore_index
        """
        logger.info("=" * 60)
        logger.info("ğŸ“‹ é˜¶æ®µ: READMEåˆ†æå’Œç”Ÿæˆ (ReadmeAnalysisNode)")
        shared["current_stage"] = "readme_analysis"

        local_path = shared.get("local_path")
        repo_info = shared.get("repo_info", {})
        code_analysis = shared.get("code_analysis", [])
        vectorstore_index = shared.get("vectorstore_index")

        if not local_path:
            logger.error("âŒ READMEåˆ†æéœ€è¦æä¾›æœ¬åœ°ä»“åº“è·¯å¾„")
            raise LLMParsingError("Local path is required for README analysis")

        local_path = Path(local_path)
        if not local_path.exists():
            logger.error(f"âŒ æœ¬åœ°ä»“åº“è·¯å¾„ä¸å­˜åœ¨: {local_path}")
            raise LLMParsingError(f"Local repository path does not exist: {local_path}")

        # æŸ¥æ‰¾ç°æœ‰çš„READMEæ–‡ä»¶
        existing_readme = self._find_existing_readme(local_path)
        existing_readme_content = ""

        if existing_readme:
            try:
                with open(existing_readme, "r", encoding="utf-8") as f:
                    existing_readme_content = f.read()
                logger.info(f"ğŸ“„ æ‰¾åˆ°ç°æœ‰READMEæ–‡ä»¶: {existing_readme.name}")
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–READMEæ–‡ä»¶å¤±è´¥: {str(e)}")

        # å‡†å¤‡åˆ†ææ•°æ®
        analysis_data = {
            "local_path": local_path,
            "repo_info": repo_info,
            "code_analysis": code_analysis,
            "vectorstore_index": vectorstore_index,
            "existing_readme_path": str(existing_readme) if existing_readme else None,
            "existing_readme_content": existing_readme_content,
            "readme_quality": self._assess_readme_quality(existing_readme_content),
        }

        logger.info(f"ğŸ” å‡†å¤‡åˆ†æREADME: ç°æœ‰å†…å®¹é•¿åº¦={len(existing_readme_content)}")
        return analysis_data

    def _find_existing_readme(self, repo_path: Path) -> Optional[Path]:
        """æŸ¥æ‰¾ç°æœ‰çš„READMEæ–‡ä»¶"""
        readme_patterns = [
            "README.md",
            "readme.md",
            "Readme.md",
            "README.MD",
            "README.txt",
            "readme.txt",
            "README.rst",
            "readme.rst",
            "README",
            "readme",
        ]

        for pattern in readme_patterns:
            readme_path = repo_path / pattern
            if readme_path.exists() and readme_path.is_file():
                return readme_path

        return None

    def _assess_readme_quality(self, content: str) -> Dict[str, Any]:
        """è¯„ä¼°READMEè´¨é‡"""
        if not content:
            return {
                "quality_score": 0,
                "has_content": False,
                "word_count": 0,
                "sections": [],
                "needs_improvement": True,
                "improvement_reason": "æ²¡æœ‰READMEæ–‡ä»¶",
            }

        content = content.strip()
        word_count = len(content.split())
        lines = content.split("\n")

        # æ£€æŸ¥å¸¸è§çš„READMEç« èŠ‚
        sections = []
        section_patterns = [
            r"#.*(?:installation|å®‰è£…)",
            r"#.*(?:usage|ä½¿ç”¨|ç”¨æ³•)",
            r"#.*(?:features|åŠŸèƒ½|ç‰¹æ€§)",
            r"#.*(?:requirements|ä¾èµ–|è¦æ±‚)",
            r"#.*(?:contributing|è´¡çŒ®)",
            r"#.*(?:license|è®¸å¯|æˆæƒ)",
            r"#.*(?:documentation|æ–‡æ¡£)",
            r"#.*(?:examples|ç¤ºä¾‹|ä¾‹å­)",
        ]

        import re

        for line in lines:
            for pattern in section_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    sections.append(line.strip())
                    break

        # è´¨é‡è¯„åˆ†é€»è¾‘
        quality_score = 0
        if word_count > 50:
            quality_score += 30
        if word_count > 200:
            quality_score += 20
        if len(sections) >= 3:
            quality_score += 30
        if len(sections) >= 5:
            quality_score += 20

        needs_improvement = quality_score < 70 or word_count < 100

        improvement_reason = ""
        if word_count < 50:
            improvement_reason = "å†…å®¹è¿‡å°‘ï¼Œç¼ºä¹è¯¦ç»†è¯´æ˜"
        elif word_count < 100:
            improvement_reason = "å†…å®¹è¾ƒå°‘ï¼Œéœ€è¦æ›´å¤šè¯¦ç»†ä¿¡æ¯"
        elif len(sections) < 3:
            improvement_reason = "ç¼ºå°‘é‡è¦ç« èŠ‚ï¼ˆå¦‚å®‰è£…ã€ä½¿ç”¨è¯´æ˜ç­‰ï¼‰"
        elif quality_score < 70:
            improvement_reason = "æ•´ä½“è´¨é‡éœ€è¦æå‡ï¼Œç¼ºå°‘å®Œæ•´çš„é¡¹ç›®è¯´æ˜"

        return {
            "quality_score": quality_score,
            "has_content": True,
            "word_count": word_count,
            "sections": sections,
            "needs_improvement": needs_improvement,
            "improvement_reason": improvement_reason,
        }

    async def exec_async(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡ŒREADMEåˆ†æå’Œç”Ÿæˆ
        """
        try:
            repo_info = analysis_data["repo_info"]
            code_analysis = analysis_data["code_analysis"]
            existing_readme_content = analysis_data["existing_readme_content"]
            readme_quality = analysis_data["readme_quality"]
            vectorstore_index = analysis_data["vectorstore_index"]

            logger.info(f"ğŸ” å¼€å§‹READMEåˆ†æ: è´¨é‡è¯„åˆ†={readme_quality['quality_score']}")

            # 1. è·å–é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯
            project_context = await self._get_project_context(repo_info, code_analysis, vectorstore_index)

            # 2. ç”Ÿæˆæˆ–æ”¹è¿›README
            if readme_quality["needs_improvement"]:
                logger.info(f"ğŸ“ éœ€è¦æ”¹è¿›README: {readme_quality['improvement_reason']}")

                if readme_quality["has_content"]:
                    # æ”¹è¿›ç°æœ‰README
                    new_readme_content = await self._improve_existing_readme(
                        existing_readme_content, project_context, repo_info, readme_quality
                    )
                    action_type = "improved"
                else:
                    # ç”Ÿæˆå…¨æ–°README
                    new_readme_content = await self._generate_new_readme(project_context, repo_info)
                    action_type = "generated"
            else:
                logger.info("âœ… ç°æœ‰READMEè´¨é‡è‰¯å¥½ï¼Œè¿›è¡Œè½»å¾®ä¼˜åŒ–")
                new_readme_content = await self._optimize_existing_readme(
                    existing_readme_content, project_context, repo_info
                )
                action_type = "optimized"

            return {
                "readme_content": new_readme_content,
                "action_type": action_type,
                "original_quality": readme_quality,
                "project_context": project_context,
                "success": True,
            }

        except Exception as e:
            logger.error(f"âŒ READMEåˆ†æå¤±è´¥: {str(e)}")
            return {"readme_content": "", "action_type": "failed", "error": str(e), "success": False}

    async def _get_project_context(
        self, repo_info: Dict[str, Any], code_analysis: List[Dict[str, Any]], vectorstore_index: Optional[str]
    ) -> Dict[str, Any]:
        """è·å–é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            # åŸºç¡€é¡¹ç›®ä¿¡æ¯
            context = {
                "repo_name": repo_info.get("name", "Unknown"),
                "full_name": repo_info.get("full_name", ""),
                "description": repo_info.get("description", ""),
                "language": repo_info.get("language", ""),
                "topics": repo_info.get("topics", []),
                "license": repo_info.get("license", {}).get("name", "") if repo_info.get("license") else "",
                "stars": repo_info.get("stargazers_count", 0),
                "forks": repo_info.get("forks_count", 0),
            }

            # ä»ä»£ç åˆ†æä¸­æå–å…³é”®ä¿¡æ¯
            if code_analysis:
                context.update(self._extract_code_insights(code_analysis))

            # å¦‚æœæœ‰å‘é‡å­˜å‚¨ï¼Œè·å–é¡¹ç›®æ¦‚è§ˆ
            if vectorstore_index:
                project_overview = await self._get_project_overview_from_rag(vectorstore_index, context)
                context["project_overview"] = project_overview

            return context

        except Exception as e:
            logger.warning(f"âš ï¸ è·å–é¡¹ç›®ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
            return {
                "repo_name": repo_info.get("name", "Unknown"),
                "description": repo_info.get("description", ""),
                "language": repo_info.get("language", ""),
            }

    def _extract_code_insights(self, code_analysis: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä»ä»£ç åˆ†æä¸­æå–å…³é”®æ´å¯Ÿ"""
        insights = {
            "total_files": len(code_analysis),
            "languages": set(),
            "main_components": [],
            "key_features": [],
            "architecture_patterns": [],
        }

        for file_analysis in code_analysis:
            # æ”¶é›†ç¼–ç¨‹è¯­è¨€
            if file_analysis.get("language"):
                insights["languages"].add(file_analysis["language"])

            # åˆ†æå…³é”®ç»„ä»¶
            analysis_items = file_analysis.get("analysis_items", [])
            for item in analysis_items:
                title = item.get("title", "")
                description = item.get("description", "")

                # è¯†åˆ«ä¸»è¦ç»„ä»¶ï¼ˆç±»ã€ä¸»è¦å‡½æ•°ç­‰ï¼‰
                if any(keyword in title.lower() for keyword in ["class", "main", "app", "server", "client", "manager"]):
                    insights["main_components"].append(
                        {
                            "name": title,
                            "description": description[:100] + "..." if len(description) > 100 else description,
                            "file": file_analysis.get("file_path", ""),
                        }
                    )

                # è¯†åˆ«æ¶æ„æ¨¡å¼
                if any(
                    pattern in description.lower()
                    for pattern in ["singleton", "factory", "observer", "mvc", "api", "rest"]
                ):
                    insights["architecture_patterns"].append(title)

        insights["languages"] = list(insights["languages"])
        insights["main_components"] = insights["main_components"][:10]  # é™åˆ¶æ•°é‡
        insights["architecture_patterns"] = list(set(insights["architecture_patterns"]))[:5]

        return insights

    async def _get_project_overview_from_rag(self, vectorstore_index: str, context: Dict[str, Any]) -> str:
        """ä½¿ç”¨RAGè·å–é¡¹ç›®æ¦‚è§ˆ"""
        try:
            # æ„å»ºæŸ¥è¯¢æ¥è·å–é¡¹ç›®æ¦‚è§ˆ
            queries = [
                f"{context['repo_name']} é¡¹ç›®æ¦‚è¿° åŠŸèƒ½ç‰¹æ€§",
                f"{context['language']} é¡¹ç›®æ¶æ„ è®¾è®¡æ¨¡å¼",
                "ä¸»è¦åŠŸèƒ½ æ ¸å¿ƒç‰¹æ€§ ä½¿ç”¨åœºæ™¯",
                "å®‰è£…é…ç½® ä½¿ç”¨æ–¹æ³• ç¤ºä¾‹",
            ]

            overview_parts = []
            for query in queries:
                try:
                    results = self.rag_client.search_knowledge(query=query, index_name=vectorstore_index, top_k=3)

                    for result in results:
                        doc = result.get("document", {})
                        content = doc.get("content", "")
                        if content and len(content) > 50:
                            overview_parts.append(content[:200] + "...")

                except Exception as e:
                    logger.warning(f"RAGæŸ¥è¯¢å¤±è´¥: {query} - {str(e)}")
                    continue

            return "\n".join(overview_parts[:5]) if overview_parts else ""

        except Exception as e:
            logger.warning(f"âš ï¸ è·å–é¡¹ç›®æ¦‚è§ˆå¤±è´¥: {str(e)}")
            return ""

    async def _generate_new_readme(self, project_context: Dict[str, Any], repo_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆå…¨æ–°çš„README"""
        prompt = self._build_readme_generation_prompt(project_context, repo_info, mode="generate")

        try:
            response = await self.llm_parser._make_api_request(prompt)
            return response.strip()
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆREADMEå¤±è´¥: {str(e)}")
            return self._create_fallback_readme(project_context, repo_info)

    async def _improve_existing_readme(
        self,
        existing_content: str,
        project_context: Dict[str, Any],
        repo_info: Dict[str, Any],
        readme_quality: Dict[str, Any],
    ) -> str:
        """æ”¹è¿›ç°æœ‰README"""
        prompt = self._build_readme_improvement_prompt(existing_content, project_context, repo_info, readme_quality)

        try:
            response = await self.llm_parser._make_api_request(prompt)
            return response.strip()
        except Exception as e:
            logger.error(f"âŒ æ”¹è¿›READMEå¤±è´¥: {str(e)}")
            return existing_content  # è¿”å›åŸå†…å®¹ä½œä¸ºå¤‡é€‰

    async def _optimize_existing_readme(
        self, existing_content: str, project_context: Dict[str, Any], repo_info: Dict[str, Any]
    ) -> str:
        """ä¼˜åŒ–ç°æœ‰README"""
        prompt = self._build_readme_optimization_prompt(existing_content, project_context, repo_info)

        try:
            response = await self.llm_parser._make_api_request(prompt)
            return response.strip()
        except Exception as e:
            logger.error(f"âŒ ä¼˜åŒ–READMEå¤±è´¥: {str(e)}")
            return existing_content  # è¿”å›åŸå†…å®¹ä½œä¸ºå¤‡é€‰

    def _build_readme_generation_prompt(
        self, project_context: Dict[str, Any], repo_info: Dict[str, Any], mode: str = "generate"
    ) -> str:
        """æ„å»ºREADMEç”Ÿæˆçš„prompt"""
        repo_name = project_context.get("repo_name", "Unknown")
        description = project_context.get("description", "")
        language = project_context.get("language", "")
        languages = project_context.get("languages", [])
        main_components = project_context.get("main_components", [])
        project_overview = project_context.get("project_overview", "")

        components_text = ""
        if main_components:
            components_text = "\nä¸»è¦ç»„ä»¶:\n" + "\n".join(
                [f"- {comp['name']}: {comp['description']}" for comp in main_components[:5]]
            )

        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£ç¼–å†™ä¸“å®¶ã€‚è¯·ä¸ºGitHubé¡¹ç›® "{repo_name}" ç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€ä¸“ä¸šã€è¯¦ç»†çš„ä¸­æ–‡README.mdæ–‡æ¡£ã€‚

é¡¹ç›®ä¿¡æ¯:
- é¡¹ç›®åç§°: {repo_name}
- é¡¹ç›®æè¿°: {description}
- ä¸»è¦è¯­è¨€: {language}
- æ”¯æŒè¯­è¨€: {', '.join(languages) if languages else language}
- Stars: {project_context.get('stars', 0)}
- Forks: {project_context.get('forks', 0)}
- è®¸å¯è¯: {project_context.get('license', 'Unknown')}

{components_text}

é¡¹ç›®æ¦‚è§ˆ:
{project_overview}

è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ä¸­æ–‡README.mdæ–‡æ¡£ï¼ŒåŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š

1. **é¡¹ç›®æ ‡é¢˜å’Œå¾½ç« ** - åŒ…å«é¡¹ç›®åç§°ã€ç®€çŸ­ä¸­æ–‡æè¿°ã€ç›¸å…³å¾½ç« 
2. **é¡¹ç›®ç®€ä»‹** - ç”¨ä¸­æ–‡è¯¦ç»†ä»‹ç»é¡¹ç›®çš„ç›®çš„ã€ç‰¹æ€§å’Œä»·å€¼
3. **åŠŸèƒ½ç‰¹æ€§** - ç”¨ä¸­æ–‡åˆ—å‡ºä¸»è¦åŠŸèƒ½å’Œç‰¹è‰²
4. **å¿«é€Ÿå¼€å§‹** - åŒ…å«ä¸­æ–‡çš„å®‰è£…ã€é…ç½®å’ŒåŸºæœ¬ä½¿ç”¨æ­¥éª¤
5. **å®‰è£…æŒ‡å—** - è¯¦ç»†çš„ä¸­æ–‡å®‰è£…è¯´æ˜å’Œä¾èµ–è¦æ±‚
6. **ä½¿ç”¨è¯´æ˜** - è¯¦ç»†çš„ä¸­æ–‡ä½¿ç”¨æ–¹æ³•å’Œç¤ºä¾‹ä»£ç 
7. **APIæ–‡æ¡£** - å¦‚æœé€‚ç”¨ï¼Œæä¾›ä¸­æ–‡APIæ¥å£è¯´æ˜
8. **é…ç½®è¯´æ˜** - ä¸­æ–‡é…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡è¯´æ˜
9. **ç¤ºä¾‹** - å®é™…ä½¿ç”¨ç¤ºä¾‹å’Œä»£ç ç‰‡æ®µï¼ˆæ³¨é‡Šç”¨ä¸­æ–‡ï¼‰
10. **è´¡çŒ®æŒ‡å—** - å¦‚ä½•å‚ä¸é¡¹ç›®è´¡çŒ®çš„ä¸­æ–‡è¯´æ˜
11. **è®¸å¯è¯** - è®¸å¯è¯ä¿¡æ¯
12. **è”ç³»æ–¹å¼** - ç»´æŠ¤è€…ä¿¡æ¯å’Œæ”¯æŒæ¸ é“

é‡è¦è¦æ±‚ï¼š
- **å¿…é¡»ä½¿ç”¨ä¸­æ–‡ç¼–å†™æ‰€æœ‰æ–‡æ¡£å†…å®¹**
- ä½¿ç”¨ä¸“ä¸šçš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£å†™ä½œé£æ ¼
- å†…å®¹è¦è¯¦ç»†ã€å‡†ç¡®ã€å®ç”¨
- åŒ…å«é€‚å½“çš„ä»£ç ç¤ºä¾‹å’Œé…ç½®ç¤ºä¾‹ï¼ˆä»£ç æ³¨é‡Šç”¨ä¸­æ–‡ï¼‰
- ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—
- ç¡®ä¿æ–‡æ¡£ç»“æ„æ¸…æ™°ï¼Œæ˜“äºä¸­æ–‡è¯»è€…é˜…è¯»å’Œå¯¼èˆª
- æ ¹æ®é¡¹ç›®çš„å®é™…æŠ€æœ¯æ ˆå’Œæ¶æ„ç‰¹ç‚¹å®šåˆ¶ä¸­æ–‡å†…å®¹
- æ‰€æœ‰ç« èŠ‚æ ‡é¢˜ã€è¯´æ˜æ–‡å­—ã€ç¤ºä¾‹æ³¨é‡Šéƒ½å¿…é¡»æ˜¯ä¸­æ–‡

è¯·ç›´æ¥è¾“å‡ºå®Œæ•´çš„ä¸­æ–‡README.mdå†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
"""

    def _build_readme_improvement_prompt(
        self,
        existing_content: str,
        project_context: Dict[str, Any],
        repo_info: Dict[str, Any],
        readme_quality: Dict[str, Any],
    ) -> str:
        """æ„å»ºREADMEæ”¹è¿›çš„prompt"""
        improvement_reason = readme_quality.get("improvement_reason", "")
        missing_sections = self._identify_missing_sections(existing_content)

        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£ç¼–å†™ä¸“å®¶ã€‚è¯·æ”¹è¿›ä»¥ä¸‹GitHubé¡¹ç›®çš„README.mdæ–‡æ¡£ï¼Œç”Ÿæˆä¸­æ–‡ç‰ˆæœ¬ã€‚

é¡¹ç›®ä¿¡æ¯:
- é¡¹ç›®åç§°: {project_context.get("repo_name", "Unknown")}
- é¡¹ç›®æè¿°: {project_context.get("description", "")}
- ä¸»è¦è¯­è¨€: {project_context.get("language", "")}

å½“å‰READMEè´¨é‡è¯„ä¼°:
- è´¨é‡è¯„åˆ†: {readme_quality.get("quality_score", 0)}/100
- æ”¹è¿›åŸå› : {improvement_reason}
- ç¼ºå°‘çš„ç« èŠ‚: {', '.join(missing_sections) if missing_sections else 'æ— '}

ç°æœ‰READMEå†…å®¹:
```markdown
{existing_content}
```

é¡¹ç›®æŠ€æœ¯ä¿¡æ¯:
{self._format_project_context_for_prompt(project_context)}

è¯·æ”¹è¿›è¿™ä¸ªREADMEæ–‡æ¡£ï¼Œè¦æ±‚ï¼š
1. **å¿…é¡»ä½¿ç”¨ä¸­æ–‡ç¼–å†™æ‰€æœ‰æ–‡æ¡£å†…å®¹**
2. ä¿ç•™ç°æœ‰çš„æœ‰ä»·å€¼å†…å®¹ï¼Œä½†ç¿»è¯‘æˆä¸­æ–‡
3. è¡¥å……ç¼ºå¤±çš„é‡è¦ç« èŠ‚ï¼ˆç”¨ä¸­æ–‡ï¼‰
4. æ”¹è¿›å†…å®¹çš„è¯¦ç»†ç¨‹åº¦å’Œä¸“ä¸šæ€§ï¼ˆç”¨ä¸­æ–‡è¡¨è¾¾ï¼‰
5. ç¡®ä¿æ–‡æ¡£ç»“æ„æ¸…æ™°å®Œæ•´
6. æ·»åŠ å¿…è¦çš„ä»£ç ç¤ºä¾‹å’Œä½¿ç”¨è¯´æ˜ï¼ˆæ³¨é‡Šç”¨ä¸­æ–‡ï¼‰
7. ä½¿ç”¨ä¸“ä¸šçš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£å†™ä½œé£æ ¼
8. æ‰€æœ‰ç« èŠ‚æ ‡é¢˜ã€è¯´æ˜æ–‡å­—ã€ç¤ºä¾‹æ³¨é‡Šéƒ½å¿…é¡»æ˜¯ä¸­æ–‡
9. å¦‚æœåŸæ–‡æ˜¯è‹±æ–‡ï¼Œè¯·ç¿»è¯‘æˆå‡†ç¡®çš„ä¸­æ–‡æŠ€æœ¯æœ¯è¯­

è¯·ç›´æ¥è¾“å‡ºæ”¹è¿›åçš„å®Œæ•´ä¸­æ–‡README.mdå†…å®¹ã€‚
"""

    def _build_readme_optimization_prompt(
        self, existing_content: str, project_context: Dict[str, Any], repo_info: Dict[str, Any]
    ) -> str:
        """æ„å»ºREADMEä¼˜åŒ–çš„prompt"""
        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£ç¼–å†™ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹README.mdæ–‡æ¡£è¿›è¡Œä¼˜åŒ–å’Œå®Œå–„ï¼Œè¾“å‡ºä¸­æ–‡ç‰ˆæœ¬ã€‚

é¡¹ç›®ä¿¡æ¯:
- é¡¹ç›®åç§°: {project_context.get("repo_name", "Unknown")}
- é¡¹ç›®æè¿°: {project_context.get("description", "")}

ç°æœ‰READMEå†…å®¹:
```markdown
{existing_content}
```

è¯·è¿›è¡Œä»¥ä¸‹ä¼˜åŒ–ï¼š
1. **å¿…é¡»ä½¿ç”¨ä¸­æ–‡ç¼–å†™æ‰€æœ‰æ–‡æ¡£å†…å®¹**
2. æ”¹è¿›è¯­è¨€è¡¨è¾¾ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šå’Œæ¸…æ™°ï¼ˆç”¨ä¸­æ–‡ï¼‰
3. ä¼˜åŒ–æ–‡æ¡£ç»“æ„å’Œæ ¼å¼
4. è¡¥å……å¿…è¦çš„æŠ€æœ¯ç»†èŠ‚ï¼ˆç”¨ä¸­æ–‡è¯´æ˜ï¼‰
5. ç¡®ä¿ä»£ç ç¤ºä¾‹çš„å‡†ç¡®æ€§ï¼ˆæ³¨é‡Šç”¨ä¸­æ–‡ï¼‰
6. æ”¹è¿›ç« èŠ‚ç»„ç»‡å’Œå¯¼èˆª
7. å¦‚æœåŸæ–‡æ˜¯è‹±æ–‡ï¼Œè¯·ç¿»è¯‘æˆå‡†ç¡®çš„ä¸­æ–‡æŠ€æœ¯æœ¯è¯­
8. æ‰€æœ‰ç« èŠ‚æ ‡é¢˜ã€è¯´æ˜æ–‡å­—ã€ç¤ºä¾‹æ³¨é‡Šéƒ½å¿…é¡»æ˜¯ä¸­æ–‡

è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„å®Œæ•´ä¸­æ–‡README.mdå†…å®¹ã€‚
"""

    def _identify_missing_sections(self, content: str) -> List[str]:
        """è¯†åˆ«ç¼ºå¤±çš„READMEç« èŠ‚"""
        if not content:
            return ["æ‰€æœ‰ç« èŠ‚"]

        content_lower = content.lower()
        missing = []

        required_sections = {
            "å®‰è£…": ["install", "å®‰è£…", "setup"],
            "ä½¿ç”¨": ["usage", "ä½¿ç”¨", "ç”¨æ³•", "how to"],
            "åŠŸèƒ½": ["feature", "åŠŸèƒ½", "ç‰¹æ€§"],
            "ç¤ºä¾‹": ["example", "ç¤ºä¾‹", "ä¾‹å­"],
            "è´¡çŒ®": ["contribut", "è´¡çŒ®"],
            "è®¸å¯": ["license", "è®¸å¯", "æˆæƒ"],
        }

        for section_name, keywords in required_sections.items():
            if not any(keyword in content_lower for keyword in keywords):
                missing.append(section_name)

        return missing

    def _format_project_context_for_prompt(self, context: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯ç”¨äºprompt"""
        lines = []

        if context.get("languages"):
            lines.append(f"ç¼–ç¨‹è¯­è¨€: {', '.join(context['languages'])}")

        if context.get("main_components"):
            lines.append("ä¸»è¦ç»„ä»¶:")
            for comp in context["main_components"][:5]:
                lines.append(f"  - {comp['name']}: {comp['description']}")

        if context.get("architecture_patterns"):
            lines.append(f"æ¶æ„æ¨¡å¼: {', '.join(context['architecture_patterns'])}")

        if context.get("project_overview"):
            lines.append(f"é¡¹ç›®æ¦‚è§ˆ: {context['project_overview'][:300]}...")

        return "\n".join(lines) if lines else "æ— é¢å¤–æŠ€æœ¯ä¿¡æ¯"

    def _create_fallback_readme(self, project_context: Dict[str, Any], repo_info: Dict[str, Any]) -> str:
        """åˆ›å»ºå¤‡ç”¨READMEå†…å®¹"""
        repo_name = project_context.get("repo_name", "Unknown Project")
        description = project_context.get("description", "")
        language = project_context.get("language", "")

        return f"""# {repo_name}

{description}

## é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªåŸºäº {language} çš„é¡¹ç›®ã€‚

## åŠŸèƒ½ç‰¹æ€§

- å¾…è¡¥å……åŠŸèƒ½ç‰¹æ€§
- æ”¯æŒå¤šç§æ“ä½œæ¨¡å¼
- æä¾›å®Œæ•´çš„APIæ¥å£

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- {language} è¿è¡Œç¯å¢ƒ
- ç›¸å…³ä¾èµ–åŒ…

### å®‰è£…æ­¥éª¤

```bash
# å…‹éš†é¡¹ç›®ä»“åº“
git clone <repository-url>
cd {repo_name.lower().replace(' ', '-')}

# å®‰è£…é¡¹ç›®ä¾èµ–
# è¯·æ ¹æ®é¡¹ç›®å®é™…æƒ…å†µæ·»åŠ å®‰è£…å‘½ä»¤
```

### åŸºæœ¬ä½¿ç”¨

```bash
# è¿è¡Œé¡¹ç›®
# è¯·æ ¹æ®é¡¹ç›®å®é™…æƒ…å†µæ·»åŠ ä½¿ç”¨ç¤ºä¾‹
```

## é…ç½®è¯´æ˜

è¯·æ ¹æ®é¡¹ç›®éœ€è¦è¿›è¡Œç›¸åº”é…ç½®ã€‚

## ç¤ºä¾‹ä»£ç 

```{language.lower()}
# ç¤ºä¾‹ä»£ç 
# è¯·æ ¹æ®é¡¹ç›®å®é™…æƒ…å†µæ·»åŠ ä»£ç ç¤ºä¾‹
```

## è´¡çŒ®æŒ‡å—

æ¬¢è¿å‚ä¸é¡¹ç›®è´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. å‘èµ· Pull Request

## é—®é¢˜åé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issueã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ç›¸åº”å¼€æºè®¸å¯è¯ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹ LICENSE æ–‡ä»¶ã€‚
"""

    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """
        ä¿å­˜ç”Ÿæˆçš„READMEæ–‡ä»¶åˆ°ç»“æœç›®å½•

        Data Access:
        - Write: shared.enhanced_readme_path
        - Write: æœ¬åœ°ç£ç›˜æ–‡ä»¶ (enhanced_readme.md)
        """
        try:
            if not exec_res.get("success"):
                logger.error(f"âŒ READMEåˆ†æå¤±è´¥: {exec_res.get('error', 'Unknown error')}")
                return "default"

            readme_content = exec_res.get("readme_content", "")
            action_type = exec_res.get("action_type", "unknown")

            if not readme_content:
                logger.warning("âš ï¸ ç”Ÿæˆçš„READMEå†…å®¹ä¸ºç©º")
                return "default"

            # è·å–ä»“åº“ä¿¡æ¯
            repo_info = prep_res["repo_info"]
            repo_name = repo_info.get("name", "unknown")

            # åˆ›å»ºä»“åº“ä¸“ç”¨çš„ç»“æœç›®å½•
            from pathlib import Path

            repo_results_dir = Path("./data/results") / repo_name
            repo_results_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜å¢å¼ºçš„READMEæ–‡ä»¶
            enhanced_readme_path = repo_results_dir / "enhanced_readme.md"

            with open(enhanced_readme_path, "w", encoding="utf-8") as f:
                f.write(readme_content)

            # æ›´æ–°å…±äº«æ•°æ®
            shared["enhanced_readme_path"] = str(enhanced_readme_path)
            shared["readme_action_type"] = action_type
            shared["readme_analysis_result"] = exec_res

            # è®°å½•æ“ä½œç»“æœ
            action_messages = {
                "generated": "ç”Ÿæˆäº†å…¨æ–°çš„READMEæ–‡æ¡£",
                "improved": "æ”¹è¿›äº†ç°æœ‰çš„READMEæ–‡æ¡£",
                "optimized": "ä¼˜åŒ–äº†ç°æœ‰çš„READMEæ–‡æ¡£",
                "failed": "READMEåˆ†æå¤±è´¥",
            }

            message = action_messages.get(action_type, f"å®Œæˆäº†README {action_type}")
            logger.info(f"âœ… {message}: {enhanced_readme_path}")

            # ä¿å­˜åˆ†æå…ƒæ•°æ®
            await self._save_readme_metadata(repo_results_dir, exec_res, prep_res)

            return "default"

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜READMEæ–‡ä»¶å¤±è´¥: {str(e)}")
            return "default"

    async def _save_readme_metadata(self, results_dir: Path, exec_res: Dict[str, Any], prep_res: Dict[str, Any]):
        """ä¿å­˜READMEåˆ†æçš„å…ƒæ•°æ®"""
        try:
            import json
            from datetime import datetime

            metadata = {
                "analysis_time": datetime.now().isoformat(),
                "action_type": exec_res.get("action_type", "unknown"),
                "original_quality": exec_res.get("original_quality", {}),
                "project_context": exec_res.get("project_context", {}),
                "readme_length": len(exec_res.get("readme_content", "")),
                "success": exec_res.get("success", False),
            }

            if exec_res.get("error"):
                metadata["error"] = exec_res["error"]

            metadata_path = results_dir / "readme_analysis_metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            logger.info(f"ğŸ“„ READMEåˆ†æå…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")

        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜READMEå…ƒæ•°æ®å¤±è´¥: {str(e)}")
