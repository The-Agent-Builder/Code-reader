"""
æœ¬åœ°æ–‡ä»¶å¤¹åˆ†æä¸»æµç¨‹
æ•´åˆæ‰€æœ‰èŠ‚ç‚¹ï¼Œå®ç°å®Œæ•´çš„ä»£ç ä»“åº“è§£ææµç¨‹
"""

from typing import Dict, Any, List
from pocketflow import AsyncFlow

from ..nodes import (
    LocalFolderNode,
    VectorizeRepoNode,
    CodeParsingBatchNode,
    ReadmeAnalysisNode,
    SaveResultsNode,
    SaveToMySQLNode,
)
from ..utils.logger import logger


class GitHubAnalysisFlow(AsyncFlow):
    """æœ¬åœ°æ–‡ä»¶å¤¹åˆ†æä¸»æµç¨‹ï¼ˆåŸGitHubåˆ†ææµç¨‹ï¼‰"""

    def __init__(self):
        super().__init__()

        # åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
        self.local_folder_node = LocalFolderNode()
        
        self.vectorize_node = VectorizeRepoNode()
        self.code_parse_node = CodeParsingBatchNode()
        self.readme_analysis_node = ReadmeAnalysisNode()
        self.save_results_node = SaveResultsNode()
        self.save_mysql_node = SaveToMySQLNode()

        # æ„å»ºæµç¨‹é“¾
        self._build_flow()

    def _build_flow(self):
        """æ„å»ºåˆ†ææµç¨‹"""
        # è®¾ç½®èµ·å§‹èŠ‚ç‚¹
        self.start(self.local_folder_node)

        # æ„å»ºèŠ‚ç‚¹é“¾ï¼šæœ¬åœ°æ–‡ä»¶å¤¹ -> å‘é‡åŒ– -> ä»£ç è§£æ -> READMEåˆ†æ -> ä¿å­˜ç»“æœ
        (
            self.local_folder_node
            >> self.vectorize_node
            >> self.code_parse_node
            >> self.readme_analysis_node
            >> self.save_results_node
            >> self.save_mysql_node
        )

        logger.info("Local folder analysis flow constructed")

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """æµç¨‹é¢„å¤„ç†"""
        logger.info("ğŸš€ ========== å¼€å§‹æœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹ ==========")
        logger.info("ğŸ“‹ é˜¶æ®µ: æµç¨‹åˆå§‹åŒ– (GitHubAnalysisFlow.prep_async)")

        # éªŒè¯è¾“å…¥
        if "local_folder_path" not in shared:
            logger.error("âŒ ç¼ºå°‘æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„")
            raise ValueError("Local folder path is required")

        local_folder_path = shared.get("local_folder_path")
        if local_folder_path is None:
            logger.error("âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ä¸º None")
            raise ValueError("Local folder path cannot be None")

        if not isinstance(local_folder_path, str):
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ç±»å‹é”™è¯¯: {type(local_folder_path)}")
            raise ValueError("Local folder path must be a string")

        if not local_folder_path.strip():
            logger.error("âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ä¸ºç©º")
            raise ValueError("Local folder path cannot be empty")

        logger.info(f"ğŸ¯ ç›®æ ‡æ–‡ä»¶å¤¹: {local_folder_path}")
        logger.info("ğŸ“Š åˆ†ææ¨¡å¼: å®Œæ•´åˆ†æ (åŒ…å«å‘é‡åŒ–)")

        # åˆå§‹åŒ–å…±äº«çŠ¶æ€
        shared.setdefault("status", "processing")
        shared["current_stage"] = "initialization"

        logger.info("âœ… æµç¨‹åˆå§‹åŒ–å®Œæˆ")
        return shared

    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: str) -> Dict[str, Any]:
        """æµç¨‹åå¤„ç†"""
        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        if "result_filepath" in shared:
            shared["status"] = "completed"
            logger.info(f"Local folder analysis completed successfully: {shared['result_filepath']}")
        else:
            shared["status"] = "failed"
            logger.error("Local folder analysis failed: no result file generated")

        return shared


class QuickAnalysisFlow(AsyncFlow):
    """å¿«é€Ÿåˆ†ææµç¨‹ï¼ˆè·³è¿‡å‘é‡åŒ–ï¼‰"""

    def __init__(self, batch_size: int = 5):
        super().__init__()

        # åˆ›å»ºèŠ‚ç‚¹å®ä¾‹ï¼ˆè·³è¿‡å‘é‡åŒ–èŠ‚ç‚¹ï¼‰
        self.local_folder_node = LocalFolderNode()
        self.code_parse_node = CodeParsingBatchNode(batch_size=batch_size)
        self.readme_analysis_node = ReadmeAnalysisNode()
        self.save_results_node = SaveResultsNode()
        self.save_mysql_node = SaveToMySQLNode()

        # æ„å»ºæµç¨‹é“¾
        self._build_flow()

    def _build_flow(self):
        """æ„å»ºå¿«é€Ÿåˆ†ææµç¨‹"""
        # è®¾ç½®èµ·å§‹èŠ‚ç‚¹
        self.start(self.local_folder_node)

        # æ„å»ºèŠ‚ç‚¹é“¾ï¼šæœ¬åœ°æ–‡ä»¶å¤¹ -> ä»£ç è§£æ -> READMEåˆ†æ -> ä¿å­˜ç»“æœ
        (
            self.local_folder_node
            >> self.code_parse_node
            >> self.readme_analysis_node
            >> self.save_results_node
            >> self.save_mysql_node
        )

        logger.info("Quick analysis flow constructed")

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """æµç¨‹é¢„å¤„ç†"""
        logger.info("ğŸš€ ========== å¼€å§‹æœ¬åœ°æ–‡ä»¶å¤¹å¿«é€Ÿåˆ†ææµç¨‹ ==========")
        logger.info("ğŸ“‹ é˜¶æ®µ: æµç¨‹åˆå§‹åŒ– (QuickAnalysisFlow.prep_async)")

        # éªŒè¯è¾“å…¥
        if "local_folder_path" not in shared:
            logger.error("âŒ ç¼ºå°‘æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„")
            raise ValueError("Local folder path is required")

        local_folder_path = shared.get("local_folder_path")
        if local_folder_path is None:
            logger.error("âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ä¸º None")
            raise ValueError("Local folder path cannot be None")

        if not isinstance(local_folder_path, str):
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ç±»å‹é”™è¯¯: {type(local_folder_path)}")
            raise ValueError("Local folder path must be a string")

        if not local_folder_path.strip():
            logger.error("âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ä¸ºç©º")
            raise ValueError("Local folder path cannot be empty")

        logger.info(f"ğŸ¯ ç›®æ ‡æ–‡ä»¶å¤¹: {local_folder_path}")
        logger.info("âš¡ åˆ†ææ¨¡å¼: å¿«é€Ÿåˆ†æ (è·³è¿‡å‘é‡åŒ–)")

        shared.setdefault("status", "processing")
        shared["current_stage"] = "initialization"

        logger.info("âœ… æµç¨‹åˆå§‹åŒ–å®Œæˆ")
        return shared

    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: str) -> Dict[str, Any]:
        """æµç¨‹åå¤„ç†"""
        if "result_filepath" in shared:
            shared["status"] = "completed"
            logger.info(f"Quick analysis completed: {shared['result_filepath']}")
        else:
            shared["status"] = "failed"
            logger.error("Quick analysis failed")

        return shared


async def analyze_repository(
    local_folder_path: str, use_vectorization: bool = True, batch_size: int = 10, progress_callback=None
) -> Dict[str, Any]:
    """
    åˆ†ææœ¬åœ°æ–‡ä»¶å¤¹çš„ä¾¿æ·å‡½æ•°ï¼ˆåŸanalyze_repositoryå‡½æ•°ï¼‰

    Args:
        local_folder_path: æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„
        use_vectorization: æ˜¯å¦ä½¿ç”¨å‘é‡åŒ–ï¼ˆRAGï¼‰
        batch_size: æ‰¹å¤„ç†å¤§å°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (completed, current_file) å‚æ•°

    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    # å‡†å¤‡å…±äº«æ•°æ®
    shared = {"local_folder_path": local_folder_path, "progress_callback": progress_callback}

    # é€‰æ‹©æµç¨‹
    if use_vectorization:
        flow = GitHubAnalysisFlow()
        # è®¾ç½®æ‰¹æ¬¡å¤§å°
        if hasattr(flow.code_parse_node, "batch_size"):
            flow.code_parse_node.batch_size = batch_size
    else:
        flow = QuickAnalysisFlow(batch_size=batch_size)

    try:
        # æ‰§è¡Œåˆ†ææµç¨‹
        result = await flow.run_async(shared)

        # è¿”å›å®Œæ•´çš„å…±äº«æ•°æ®
        return shared

    except Exception as e:
        logger.error(f"Analysis failed for {local_folder_path}: {str(e)}")
        shared["status"] = "failed"
        shared["error"] = str(e)
        return shared


async def analyze_local_folder(
    local_folder_path: str, use_vectorization: bool = True, batch_size: int = 10, progress_callback=None
) -> Dict[str, Any]:
    """
    åˆ†ææœ¬åœ°æ–‡ä»¶å¤¹çš„ä¾¿æ·å‡½æ•°

    Args:
        local_folder_path: æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„
        use_vectorization: æ˜¯å¦ä½¿ç”¨å‘é‡åŒ–ï¼ˆRAGï¼‰
        batch_size: æ‰¹å¤„ç†å¤§å°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (completed, current_file) å‚æ•°

    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    # å‡†å¤‡å…±äº«æ•°æ®
    shared = {"local_folder_path": local_folder_path, "progress_callback": progress_callback}

    # åˆ›å»ºæœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹
    flow = LocalFolderAnalysisFlow(use_vectorization=use_vectorization, batch_size=batch_size)

    try:
        # æ‰§è¡Œåˆ†ææµç¨‹
        result = await flow.run_async(shared)

        # è¿”å›å®Œæ•´çš„å…±äº«æ•°æ®
        return shared

    except Exception as e:
        logger.error(f"Local folder analysis failed for {local_folder_path}: {str(e)}")
        shared["status"] = "failed"
        shared["error"] = str(e)
        return shared


# æµç¨‹å·¥å‚å‡½æ•°
def create_analysis_flow(flow_type: str = "full", **kwargs) -> AsyncFlow:
    """
    åˆ›å»ºåˆ†ææµç¨‹çš„å·¥å‚å‡½æ•°

    Args:
        flow_type: æµç¨‹ç±»å‹ ("full", "quick", "local_full", "local_quick")
                  - "full": å®Œæ•´æœ¬åœ°æ–‡ä»¶å¤¹åˆ†æï¼ˆåŒ…å«å‘é‡åŒ–ï¼‰
                  - "quick": å¿«é€Ÿæœ¬åœ°æ–‡ä»¶å¤¹åˆ†æï¼ˆè·³è¿‡å‘é‡åŒ–ï¼‰
                  - "local_full": å®Œæ•´æœ¬åœ°æ–‡ä»¶å¤¹åˆ†æï¼ˆåŒ…å«å‘é‡åŒ–ï¼‰
                  - "local_quick": å¿«é€Ÿæœ¬åœ°æ–‡ä»¶å¤¹åˆ†æï¼ˆè·³è¿‡å‘é‡åŒ–ï¼‰
        **kwargs: æµç¨‹å‚æ•°

    Returns:
        åˆ†ææµç¨‹å®ä¾‹
    """
    if flow_type == "full":
        return GitHubAnalysisFlow(**kwargs)
    elif flow_type == "quick":
        return QuickAnalysisFlow(**kwargs)
    elif flow_type == "local_full":
        return LocalFolderAnalysisFlow(use_vectorization=True, **kwargs)
    elif flow_type == "local_quick":
        return LocalFolderAnalysisFlow(use_vectorization=False, **kwargs)
    else:
        raise ValueError(f"Unknown flow type: {flow_type}. Supported types: full, quick, local_full, local_quick")


# æ‰¹é‡åˆ†æå‡½æ•°
async def analyze_repositories_batch(
    local_folder_paths: List[str], use_vectorization: bool = True, batch_size: int = 5
) -> List[Dict[str, Any]]:
    """
    æ‰¹é‡åˆ†æå¤šä¸ªæœ¬åœ°æ–‡ä»¶å¤¹

    Args:
        local_folder_paths: æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨
        use_vectorization: æ˜¯å¦ä½¿ç”¨å‘é‡åŒ–
        batch_size: æ‰¹å¤„ç†å¤§å°

    Returns:
        åˆ†æç»“æœåˆ—è¡¨
    """
    import asyncio

    results = []

    # åˆ†æ‰¹å¤„ç†æ–‡ä»¶å¤¹
    for i in range(0, len(local_folder_paths), batch_size):
        batch_paths = local_folder_paths[i : i + batch_size]

        # å¹¶è¡Œåˆ†æå½“å‰æ‰¹æ¬¡
        tasks = [analyze_repository(path, use_vectorization, batch_size) for path in batch_paths]

        batch_results = await asyncio.gather(*tasks, return_exceptions=True)

        for result in batch_results:
            if isinstance(result, Exception):
                logger.error(f"Batch analysis error: {str(result)}")
                results.append({"status": "failed", "error": str(result)})
            else:
                results.append(result)

        # æ‰¹æ¬¡é—´å»¶è¿Ÿ
        if i + batch_size < len(local_folder_paths):
            await asyncio.sleep(2)

    return results


class LocalFolderAnalysisFlow(AsyncFlow):
    """æœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹ï¼ˆè·³è¿‡GitHubä¿¡æ¯è·å–å’Œå…‹éš†ï¼‰"""

    def __init__(self, use_vectorization: bool = True, batch_size: int = 5):
        super().__init__()
        self.use_vectorization = use_vectorization

        # åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
        self.local_folder_node = LocalFolderNode()
        if use_vectorization:
            self.vectorize_node = VectorizeRepoNode()
        self.code_parse_node = CodeParsingBatchNode(batch_size=batch_size)
        self.readme_analysis_node = ReadmeAnalysisNode()
        self.save_results_node = SaveResultsNode()
        self.save_mysql_node = SaveToMySQLNode()

        # æ„å»ºæµç¨‹é“¾
        self._build_flow()

    def _build_flow(self):
        """æ„å»ºæœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹"""
        # è®¾ç½®èµ·å§‹èŠ‚ç‚¹
        self.start(self.local_folder_node)

        if self.use_vectorization:
            # å®Œæ•´æµç¨‹ï¼šæœ¬åœ°æ–‡ä»¶å¤¹ -> å‘é‡åŒ– -> ä»£ç è§£æ -> READMEåˆ†æ -> ä¿å­˜ç»“æœ
            (
                self.local_folder_node
                >> self.vectorize_node
                >> self.code_parse_node
                >> self.readme_analysis_node
                >> self.save_results_node
                >> self.save_mysql_node
            )
            logger.info("Local folder analysis flow with vectorization constructed")
        else:
            # å¿«é€Ÿæµç¨‹ï¼šæœ¬åœ°æ–‡ä»¶å¤¹ -> ä»£ç è§£æ -> READMEåˆ†æ -> ä¿å­˜ç»“æœ
            (
                self.local_folder_node
                >> self.code_parse_node
                >> self.readme_analysis_node
                >> self.save_results_node
                >> self.save_mysql_node
            )
            logger.info("Local folder quick analysis flow constructed")

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """æµç¨‹é¢„å¤„ç†"""
        logger.info("ğŸš€ ========== å¼€å§‹æœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹ ==========")
        logger.info("ğŸ“‹ é˜¶æ®µ: æµç¨‹åˆå§‹åŒ– (LocalFolderAnalysisFlow.prep_async)")

        # éªŒè¯è¾“å…¥
        if "local_folder_path" not in shared:
            logger.error("âŒ ç¼ºå°‘æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„")
            raise ValueError("Local folder path is required")

        local_folder_path = shared.get("local_folder_path")
        if local_folder_path is None:
            logger.error("âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ä¸º None")
            raise ValueError("Local folder path cannot be None")

        if not isinstance(local_folder_path, str):
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ç±»å‹é”™è¯¯: {type(local_folder_path)}")
            raise ValueError("Local folder path must be a string")

        if not local_folder_path.strip():
            logger.error("âŒ æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ä¸ºç©º")
            raise ValueError("Local folder path cannot be empty")

        logger.info(f"ğŸ¯ ç›®æ ‡æ–‡ä»¶å¤¹: {local_folder_path}")
        if self.use_vectorization:
            logger.info("ğŸ“Š åˆ†ææ¨¡å¼: å®Œæ•´åˆ†æ (åŒ…å«å‘é‡åŒ–)")
        else:
            logger.info("âš¡ åˆ†ææ¨¡å¼: å¿«é€Ÿåˆ†æ (è·³è¿‡å‘é‡åŒ–)")

        # åˆå§‹åŒ–å…±äº«çŠ¶æ€
        shared.setdefault("status", "processing")
        shared["current_stage"] = "initialization"

        logger.info("âœ… æµç¨‹åˆå§‹åŒ–å®Œæˆ")
        return shared

    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: str) -> Dict[str, Any]:
        """æµç¨‹åå¤„ç†"""
        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        if "result_filepath" in shared:
            shared["status"] = "completed"
            logger.info(f"Local folder analysis completed successfully: {shared['result_filepath']}")
        else:
            shared["status"] = "failed"
            logger.error("Local folder analysis failed: no result file generated")

        return shared
