"""
CodeParsingBatchNode æµ‹è¯•æ¨¡å—
æµ‹è¯•ä»£ç è§£ææ‰¹å¤„ç†èŠ‚ç‚¹çš„å„é¡¹åŠŸèƒ½
"""

import asyncio
import json
import sys
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.nodes.code_parsing_batch_node import CodeParsingBatchNode


class TestCodeParsingBatchNode:
    """CodeParsingBatchNode æµ‹è¯•ç±»"""

    def setup_method(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_repo_path = Path("./data/repos/PocketFlow")
        self.metadata_path = Path("./data/vectorstores/PocketFlow/metadata.json")

        # è¯»å– RAG ç´¢å¼•ä¿¡æ¯
        with open(self.metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        self.index_name = metadata["index_name"]
        self.repo_info = metadata["repo_info"]

        print(f"ğŸ”§ æµ‹è¯•å‡†å¤‡å®Œæˆ")
        print(f"   - æµ‹è¯•ä»“åº“è·¯å¾„: {self.test_repo_path}")
        print(f"   - RAG ç´¢å¼•åç§°: {self.index_name}")
        print(f"   - ä»“åº“ä¿¡æ¯: {self.repo_info['name']}")

    @pytest.mark.asyncio
    async def test_init(self):
        """æµ‹è¯•èŠ‚ç‚¹åˆå§‹åŒ–"""
        print("\nğŸ§ª æµ‹è¯• 1: èŠ‚ç‚¹åˆå§‹åŒ–")

        # ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–
        node = CodeParsingBatchNode()

        assert node.llm_parser is not None, "LLM è§£æå™¨åº”è¯¥è¢«æ­£ç¡®åˆå§‹åŒ–"
        assert node.rag_client is not None, "RAG å®¢æˆ·ç«¯åº”è¯¥è¢«æ­£ç¡®åˆå§‹åŒ–"
        assert node.batch_size > 0, "æ‰¹æ¬¡å¤§å°åº”è¯¥å¤§äº 0"
        assert node.max_concurrent > 0, "æœ€å¤§å¹¶å‘æ•°åº”è¯¥å¤§äº 0"

        print(f"   âœ… èŠ‚ç‚¹åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - æ‰¹æ¬¡å¤§å°: {node.batch_size}")
        print(f"   - æœ€å¤§å¹¶å‘: {node.max_concurrent}")

    @pytest.mark.asyncio
    async def test_prep_async_file_scanning(self):
        """æµ‹è¯•æ–‡ä»¶æ‰«æåŠŸèƒ½"""
        print("\nğŸ§ª æµ‹è¯• 2: æ–‡ä»¶æ‰«æåŠŸèƒ½")

        node = CodeParsingBatchNode()

        # å‡†å¤‡å…±äº«æ•°æ®
        shared = {
            "local_path": str(self.test_repo_path),
            "vectorstore_index": self.index_name,
            "repo_info": self.repo_info,
            "progress_callback": lambda **kwargs: print(f"   ğŸ“Š è¿›åº¦å›è°ƒ: {kwargs}"),
        }

        # æ‰§è¡Œæ–‡ä»¶æ‰«æ
        file_items = await node.prep_async(shared)

        assert len(file_items) > 0, "åº”è¯¥æ‰«æåˆ°ä»£ç æ–‡ä»¶"
        assert shared["current_stage"] == "code_analysis", "é˜¶æ®µæ ‡è¯†åº”è¯¥æ­£ç¡®è®¾ç½®"

        # æ£€æŸ¥æ–‡ä»¶é¡¹ç»“æ„
        first_item = file_items[0]
        required_keys = ["file_path", "content", "language", "full_path", "vectorstore_index"]
        for key in required_keys:
            assert key in first_item, f"æ–‡ä»¶é¡¹åº”è¯¥åŒ…å« {key} å­—æ®µ"

        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
        language_stats = {}
        for item in file_items:
            lang = item["language"]
            language_stats[lang] = language_stats.get(lang, 0) + 1

        print(f"   âœ… æ‰«æåˆ° {len(file_items)} ä¸ªä»£ç æ–‡ä»¶")
        print(f"   - è¯­è¨€åˆ†å¸ƒ: {language_stats}")
        print(f"   - ç¤ºä¾‹æ–‡ä»¶: {first_item['file_path']} ({first_item['language']})")

    @pytest.mark.asyncio
    async def test_extract_class_method_relationships(self):
        """æµ‹è¯•ç±»-æ–¹æ³•å…³ç³»æå–"""
        print("\nğŸ§ª æµ‹è¯• 3: ç±»-æ–¹æ³•å…³ç³»æå–")

        node = CodeParsingBatchNode()

        # æµ‹è¯• Python ä»£ç 
        python_code = """
class TestClass:
    def __init__(self):
        pass

    def method1(self):
        return "test"

    async def async_method(self):
        return "async"

class AnotherClass:
    def another_method(self):
        pass
"""

        relationships = node._extract_class_method_relationships(python_code, "python")

        assert "TestClass" in relationships, "åº”è¯¥æå–åˆ° TestClass"
        assert "AnotherClass" in relationships, "åº”è¯¥æå–åˆ° AnotherClass"
        assert "method1" in relationships["TestClass"], "åº”è¯¥æå–åˆ° method1"
        assert "async_method" in relationships["TestClass"], "åº”è¯¥æå–åˆ° async_method"

        print(f"   âœ… ç±»-æ–¹æ³•å…³ç³»æå–æˆåŠŸ")
        print(f"   - æå–ç»“æœ: {relationships}")

    @pytest.mark.asyncio
    async def test_extract_notebook_content(self):
        """æµ‹è¯• Jupyter Notebook å†…å®¹æå–"""
        print("\nğŸ§ª æµ‹è¯• 4: Jupyter Notebook å†…å®¹æå–")

        node = CodeParsingBatchNode()

        # æŸ¥æ‰¾æµ‹è¯•ä»“åº“ä¸­çš„ .ipynb æ–‡ä»¶
        notebook_files = list(self.test_repo_path.rglob("*.ipynb"))

        if notebook_files:
            notebook_path = notebook_files[0]
            content = node._extract_notebook_content(notebook_path)

            assert content, "åº”è¯¥æå–åˆ° Notebook å†…å®¹"
            assert "Jupyter Notebook:" in content, "åº”è¯¥åŒ…å« Notebook æ ‡è¯†"

            print(f"   âœ… Notebook å†…å®¹æå–æˆåŠŸ")
            print(f"   - æ–‡ä»¶: {notebook_path.name}")
            print(f"   - å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            print(f"   - å†…å®¹é¢„è§ˆ: {content[:200]}...")
        else:
            print(f"   âš ï¸ æµ‹è¯•ä»“åº“ä¸­æœªæ‰¾åˆ° .ipynb æ–‡ä»¶ï¼Œè·³è¿‡æ­¤æµ‹è¯•")

    @pytest.mark.asyncio
    async def test_get_rag_context_mock(self):
        """æµ‹è¯• RAG ä¸Šä¸‹æ–‡è·å–ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("\nğŸ§ª æµ‹è¯• 5: RAG ä¸Šä¸‹æ–‡è·å–ï¼ˆæ¨¡æ‹Ÿï¼‰")

        node = CodeParsingBatchNode()

        # æ¨¡æ‹Ÿ RAG å®¢æˆ·ç«¯å“åº” - ç¡®ä¿èƒ½è¢«æ­£ç¡®åˆ†ç±»
        mock_results = [
            {
                "document": {
                    "title": "AsyncParallelBatchNode ç±»",
                    "content": "class AsyncParallelBatchNode: å¼‚æ­¥å¹¶è¡Œæ‰¹å¤„ç†èŠ‚ç‚¹åŸºç±»ï¼Œæä¾› async def exec_async æ–¹æ³•",
                    "file_path": "pocketflow/__init__.py",
                }
            },
            {
                "document": {
                    "title": "BatchNode ç±»",
                    "content": "class BatchNode: æ‰¹å¤„ç†èŠ‚ç‚¹åŸºç±»ï¼ŒåŒ…å« def __init__ å’Œå…¶ä»–æ–¹æ³•",
                    "file_path": "pocketflow/__init__.py",
                }
            },
        ]

        with patch.object(node.rag_client, "search_knowledge", return_value=mock_results):
            file_item = {
                "file_path": "test_file.py",
                "content": "class TestNode(AsyncParallelBatchNode):\n    async def exec_async(self, item):\n        pass",
                "language": "python",
                "vectorstore_index": self.index_name,
            }

            context = await node._get_rag_context(file_item)

            assert context, "åº”è¯¥è·å–åˆ° RAG ä¸Šä¸‹æ–‡"

            # æ£€æŸ¥ä¸Šä¸‹æ–‡å†…å®¹ï¼Œæ›´å®½æ¾çš„æ–­è¨€
            has_relevant_info = (
                "ç›¸å…³åŸºç±»å’Œçˆ¶ç±»" in context
                or "ç›¸ä¼¼ç±»å®ç°" in context
                or "AsyncParallelBatchNode" in context
                or "BatchNode" in context
            )
            assert has_relevant_info, f"ä¸Šä¸‹æ–‡åº”è¯¥åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œå®é™…å†…å®¹: {context[:500]}"

            print(f"   âœ… RAG ä¸Šä¸‹æ–‡è·å–æˆåŠŸ")
            print(f"   - ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
            print(f"   - ä¸Šä¸‹æ–‡é¢„è§ˆ: {context[:300]}...")
            print(f"   - å®Œæ•´ä¸Šä¸‹æ–‡: {context}")

    @pytest.mark.asyncio
    async def test_exec_async_mock(self):
        """æµ‹è¯•å•æ–‡ä»¶æ‰§è¡Œï¼ˆæ¨¡æ‹Ÿ LLM è°ƒç”¨ï¼‰"""
        print("\nğŸ§ª æµ‹è¯• 6: å•æ–‡ä»¶æ‰§è¡Œï¼ˆæ¨¡æ‹Ÿ LLM è°ƒç”¨ï¼‰")

        node = CodeParsingBatchNode()

        # æ¨¡æ‹Ÿ LLM è§£æç»“æœ
        mock_result = {
            "file_path": "test_file.py",
            "analysis_items": [
                {
                    "title": "TestClass ç±»å®šä¹‰",
                    "description": "ä¸€ä¸ªæµ‹è¯•ç±»çš„å®ç°",
                    "source": "test_file.py:1-10",
                    "language": "python",
                    "code": "class TestClass:\n    def test_method(self):\n        pass",
                }
            ],
        }

        with patch.object(node.llm_parser, "parse_code_file_detailed", return_value=mock_result):
            with patch.object(node, "_get_rag_context", return_value="æ¨¡æ‹Ÿä¸Šä¸‹æ–‡"):
                file_item = {
                    "file_path": "test_file.py",
                    "content": "class TestClass:\n    def test_method(self):\n        pass",
                    "language": "python",
                    "vectorstore_index": self.index_name,
                    "progress_callback": lambda **kwargs: print(f"   ğŸ“Š è¿›åº¦: {kwargs}"),
                }

                result = await node.exec_async(file_item)

                assert result["file_path"] == "test_file.py", "æ–‡ä»¶è·¯å¾„åº”è¯¥æ­£ç¡®"
                assert "analysis_items" in result, "ç»“æœåº”è¯¥åŒ…å«åˆ†æé¡¹"
                assert len(result["analysis_items"]) > 0, "åº”è¯¥æœ‰åˆ†æé¡¹"

                print(f"   âœ… å•æ–‡ä»¶æ‰§è¡ŒæˆåŠŸ")
                print(f"   - åˆ†æé¡¹æ•°é‡: {len(result['analysis_items'])}")
                print(f"   - ç¬¬ä¸€é¡¹æ ‡é¢˜: {result['analysis_items'][0]['title']}")

    @pytest.mark.asyncio
    async def test_generate_detailed_analysis_doc(self):
        """æµ‹è¯•è¯¦ç»†åˆ†ææ–‡æ¡£ç”Ÿæˆ"""
        print("\nğŸ§ª æµ‹è¯• 7: è¯¦ç»†åˆ†ææ–‡æ¡£ç”Ÿæˆ")

        node = CodeParsingBatchNode()

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        valid_results = [
            {
                "file_path": "test1.py",
                "analysis_items": [
                    {
                        "title": "TestClass ç±»",
                        "description": "æµ‹è¯•ç±»çš„å®ç°",
                        "source": "test1.py:1-5",
                        "language": "python",
                        "code": "class TestClass:\n    pass",
                    }
                ],
            },
            {
                "file_path": "test2.js",
                "analysis_items": [
                    {
                        "title": "testFunction å‡½æ•°",
                        "description": "æµ‹è¯•å‡½æ•°çš„å®ç°",
                        "source": "test2.js:10-15",
                        "language": "javascript",
                        "code": "function testFunction() {\n    return 'test';\n}",
                    }
                ],
            },
        ]

        shared = {"repo_info": self.repo_info, "repo_url": "https://github.com/test/repo"}

        doc = node._generate_detailed_analysis_doc(valid_results, shared)

        assert doc, "åº”è¯¥ç”Ÿæˆåˆ†ææ–‡æ¡£"
        assert "TITLE:" in doc, "æ–‡æ¡£åº”è¯¥åŒ…å«æ ‡é¢˜æ ¼å¼"
        assert "DESCRIPTION:" in doc, "æ–‡æ¡£åº”è¯¥åŒ…å«æè¿°æ ¼å¼"
        assert "SOURCE:" in doc, "æ–‡æ¡£åº”è¯¥åŒ…å«æºç æ ¼å¼"
        assert "LANGUAGE:" in doc, "æ–‡æ¡£åº”è¯¥åŒ…å«è¯­è¨€æ ¼å¼"
        assert "CODE:" in doc, "æ–‡æ¡£åº”è¯¥åŒ…å«ä»£ç æ ¼å¼"

        print(f"   âœ… åˆ†ææ–‡æ¡£ç”ŸæˆæˆåŠŸ")
        print(f"   - æ–‡æ¡£é•¿åº¦: {len(doc)} å­—ç¬¦")
        print(f"   - æ–‡æ¡£é¢„è§ˆ:")
        print("   " + "\n   ".join(doc.split("\n")[:10]))

    @pytest.mark.asyncio
    async def test_post_async_mock(self):
        """æµ‹è¯•ç»“æœæ±‡æ€»å’Œä¿å­˜ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("\nğŸ§ª æµ‹è¯• 8: ç»“æœæ±‡æ€»å’Œä¿å­˜ï¼ˆæ¨¡æ‹Ÿï¼‰")

        node = CodeParsingBatchNode()

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        prep_res = []  # prep_async çš„ç»“æœï¼ˆè¿™é‡Œä¸éœ€è¦ï¼‰
        exec_res = [
            {
                "file_path": "test1.py",
                "analysis_items": [{"title": "Test1", "description": "æµ‹è¯•1"}],
                "functions": ["func1", "func2"],
                "classes": ["Class1"],
                "code_snippets": ["snippet1"],
            },
            {"file_path": "test2.py", "error": "è§£æå¤±è´¥"},  # è¿™ä¸ªä¼šè¢«è¿‡æ»¤æ‰
            {
                "file_path": "test3.js",
                "analysis_items": [{"title": "Test3", "description": "æµ‹è¯•3"}],
                "functions": ["func3"],
                "classes": [],
                "code_snippets": ["snippet2", "snippet3"],
            },
        ]

        shared = {"repo_info": self.repo_info}

        # æ¨¡æ‹Ÿæ–‡æ¡£ä¿å­˜
        with patch.object(node, "_save_analysis_document", return_value=None):
            result = await node.post_async(shared, prep_res, exec_res)

            assert result == "default", "åº”è¯¥è¿”å›é»˜è®¤å€¼"
            assert "code_analysis" in shared, "å…±äº«æ•°æ®åº”è¯¥åŒ…å«ä»£ç åˆ†æç»“æœ"
            assert "detailed_analysis_doc" in shared, "å…±äº«æ•°æ®åº”è¯¥åŒ…å«è¯¦ç»†åˆ†ææ–‡æ¡£"

            # æ£€æŸ¥è¿‡æ»¤ç»“æœ
            valid_results = shared["code_analysis"]
            assert len(valid_results) == 2, "åº”è¯¥è¿‡æ»¤æ‰é”™è¯¯ç»“æœï¼Œä¿ç•™ 2 ä¸ªæœ‰æ•ˆç»“æœ"

            print(f"   âœ… ç»“æœæ±‡æ€»æˆåŠŸ")
            print(f"   - æœ‰æ•ˆç»“æœæ•°: {len(valid_results)}")
            print(f"   - æ€»å‡½æ•°æ•°: {sum(len(r.get('functions', [])) for r in valid_results)}")
            print(f"   - æ€»ç±»æ•°: {sum(len(r.get('classes', [])) for r in valid_results)}")
            print(f"   - æ€»ä»£ç ç‰‡æ®µæ•°: {sum(len(r.get('code_snippets', [])) for r in valid_results)}")

    def test_language_detection(self):
        """æµ‹è¯•è¯­è¨€æ£€æµ‹åŠŸèƒ½"""
        print("\nğŸ§ª æµ‹è¯• 9: è¯­è¨€æ£€æµ‹åŠŸèƒ½")

        node = CodeParsingBatchNode()

        test_cases = [
            (".py", "python"),
            (".js", "javascript"),
            (".ts", "typescript"),
            (".java", "java"),
            (".cpp", "cpp"),
            (".go", "go"),
            (".rs", "rust"),
            (".unknown", "unknown"),
        ]

        for ext, expected in test_cases:
            result = node._detect_language(ext)
            assert result == expected, f"æ‰©å±•å {ext} åº”è¯¥æ£€æµ‹ä¸º {expected}ï¼Œå®é™…ä¸º {result}"

        print(f"   âœ… è¯­è¨€æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
        print(f"   - æµ‹è¯•ç”¨ä¾‹æ•°: {len(test_cases)}")

    @pytest.mark.asyncio
    async def test_full_workflow_small_sample(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹ï¼ˆå°æ ·æœ¬ï¼‰"""
        print("\nğŸ§ª æµ‹è¯• 10: å®Œæ•´å·¥ä½œæµç¨‹ï¼ˆå°æ ·æœ¬ï¼‰")

        node = CodeParsingBatchNode(batch_size=2)  # ä½¿ç”¨å°æ‰¹æ¬¡

        # å‡†å¤‡å…±äº«æ•°æ®
        shared = {
            "local_path": str(self.test_repo_path),
            "vectorstore_index": self.index_name,
            "repo_info": self.repo_info,
            "repo_url": "https://github.com/The-Pocket/PocketFlow",
            "progress_callback": lambda **kwargs: print(f"   ğŸ“Š {kwargs}"),
        }

        # æ¨¡æ‹Ÿ LLM å’Œ RAG è°ƒç”¨ä»¥é¿å…å®é™…ç½‘ç»œè¯·æ±‚
        mock_rag_context = "æ¨¡æ‹Ÿçš„ RAG ä¸Šä¸‹æ–‡ä¿¡æ¯"
        mock_llm_result = {
            "file_path": "mock_file.py",
            "analysis_items": [
                {
                    "title": "æ¨¡æ‹Ÿç±»",
                    "description": "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„ç±»åˆ†æ",
                    "source": "mock_file.py:1-10",
                    "language": "python",
                    "code": "class MockClass:\n    pass",
                }
            ],
        }

        with patch.object(node, "_get_rag_context", return_value=mock_rag_context):
            with patch.object(node.llm_parser, "parse_code_file_detailed", return_value=mock_llm_result):
                with patch.object(node, "_save_analysis_document", return_value=None):

                    # 1. å‡†å¤‡é˜¶æ®µ
                    file_items = await node.prep_async(shared)
                    print(f"   ğŸ“ å‡†å¤‡é˜¶æ®µ: æ‰«æåˆ° {len(file_items)} ä¸ªæ–‡ä»¶")

                    # 2. æ‰§è¡Œé˜¶æ®µï¼ˆåªå¤„ç†å‰å‡ ä¸ªæ–‡ä»¶ä½œä¸ºç¤ºä¾‹ï¼‰
                    sample_items = file_items[:3]  # åªå¤„ç†å‰ 3 ä¸ªæ–‡ä»¶
                    exec_results = []

                    for item in sample_items:
                        result = await node.exec_async(item)
                        exec_results.append(result)

                    print(f"   âš™ï¸ æ‰§è¡Œé˜¶æ®µ: å¤„ç†äº† {len(exec_results)} ä¸ªæ–‡ä»¶")

                    # 3. æ±‡æ€»é˜¶æ®µ
                    final_result = await node.post_async(shared, file_items, exec_results)

                    assert final_result == "default", "æœ€ç»ˆç»“æœåº”è¯¥æ­£ç¡®"
                    assert "code_analysis" in shared, "åº”è¯¥åŒ…å«ä»£ç åˆ†æç»“æœ"
                    assert "detailed_analysis_doc" in shared, "åº”è¯¥åŒ…å«è¯¦ç»†åˆ†ææ–‡æ¡£"

                    print(f"   âœ… å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•æˆåŠŸ")
                    print(f"   - æœ€ç»ˆåˆ†æç»“æœæ•°: {len(shared['code_analysis'])}")
                    print(f"   - åˆ†ææ–‡æ¡£é•¿åº¦: {len(shared['detailed_analysis_doc'])} å­—ç¬¦")


if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ CodeParsingBatchNode æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test_instance = TestCodeParsingBatchNode()
    test_instance.setup_method()

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    async def run_all_tests():
        test_methods = [
            test_instance.test_init,
            test_instance.test_prep_async_file_scanning,
            test_instance.test_extract_class_method_relationships,
            test_instance.test_extract_notebook_content,
            test_instance.test_get_rag_context_mock,
            test_instance.test_exec_async_mock,
            test_instance.test_generate_detailed_analysis_doc,
            test_instance.test_post_async_mock,
            test_instance.test_full_workflow_small_sample,
        ]

        # åŒæ­¥æµ‹è¯•
        test_instance.test_language_detection()

        # å¼‚æ­¥æµ‹è¯•
        for test_method in test_methods:
            try:
                await test_method()
            except Exception as e:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
                import traceback

                traceback.print_exc()

    # è¿è¡Œæµ‹è¯•
    asyncio.run(run_all_tests())

    print("\n" + "=" * 60)
    print("ğŸ‰ CodeParsingBatchNode æµ‹è¯•å®Œæˆ")
