"""
æµ‹è¯•æœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹
ä½¿ç”¨ CLIP ä»“åº“è¿›è¡Œæµ‹è¯•
"""

import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é¦–å…ˆåˆ›å»ºä¸€ä¸ªç®€å•çš„ dotenv æ¨¡å—æ¥è¯»å– .env æ–‡ä»¶
import os
import sys
from unittest.mock import MagicMock

def load_dotenv_simple(dotenv_path='.env', override=False):
    """ç®€å•çš„ load_dotenv å®ç°ï¼Œä» .env æ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡"""
    if not os.path.exists(dotenv_path):
        return False

    try:
        with open(dotenv_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()

                    # ç§»é™¤å¼•å·
                    if value.startswith('"') and value.endswith('"'):
                        value = value[1:-1]
                    elif value.startswith("'") and value.endswith("'"):
                        value = value[1:-1]

                    if override or key not in os.environ:
                        os.environ[key] = value
        return True
    except Exception as e:
        print(f"âš ï¸ è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")
        return False

# åˆ›å»ºæ¨¡æ‹Ÿçš„ dotenv æ¨¡å—
class MockDotenv:
    @staticmethod
    def load_dotenv(dotenv_path=None, override=False):
        if dotenv_path is None:
            return load_dotenv_simple('.env', override)
        else:
            return load_dotenv_simple(dotenv_path, override)

# å…ˆåŠ è½½ç¯å¢ƒå˜é‡
print("ğŸ“‹ ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡...")
if load_dotenv_simple('.env', override=True):
    print("âœ… æˆåŠŸä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡")
else:
    print("âš ï¸ æ— æ³•ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨é»˜è®¤å€¼")

# åˆ›å»ºæ¨¡æ‹Ÿçš„ä¾èµ–æ¨¡å—æ¥ç»•è¿‡å¯¼å…¥é—®é¢˜
sys.modules['dotenv'] = MockDotenv()

# æ¨¡æ‹Ÿå…¶ä»–ç¼ºå¤±çš„æ¨¡å—
mock_modules = [
    'aiohttp', 'openai', 'langchain', 'langchain_community', 'langchain_openai',
    'chromadb', 'requests', 'gitpython', 'git', 'jinja2', 'sqlalchemy',
    'sqlalchemy.ext', 'sqlalchemy.ext.declarative', 'sqlalchemy.orm',
    'pymysql', 'fastapi', 'uvicorn', 'pydantic'
]

for module in mock_modules:
    sys.modules[module] = MagicMock()

# ç°åœ¨å°è¯•å¯¼å…¥æµç¨‹ç±»
try:
    from src.flows.file_analysis_flow import (
        LocalFolderAnalysisFlow,
        analyze_local_folder,
        create_analysis_flow
    )
    from src.utils.logger import logger
    DEPENDENCIES_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥æµç¨‹ç±»")
except ImportError as e:
    print(f"âš ï¸ ä¾èµ–å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ”„ ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬è¿›è¡Œæµ‹è¯•...")
    DEPENDENCIES_AVAILABLE = False

    # ç®€åŒ–ç‰ˆæœ¬çš„ logger
    class SimpleLogger:
        def info(self, msg): print(f"â„¹ï¸ {msg}")
        def error(self, msg): print(f"âŒ {msg}")
        def warning(self, msg): print(f"âš ï¸ {msg}")

    logger = SimpleLogger()


async def test_local_folder_analysis():
    """æµ‹è¯•æœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹"""

    # è®¾ç½®æµ‹è¯•è·¯å¾„
    clip_repo_path = r"E:\Code\Agent1\Code-reader\data\repos\CLIP"

    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•æœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹")
    logger.info(f"ğŸ“ æµ‹è¯•ä»“åº“è·¯å¾„: {clip_repo_path}")

    # éªŒè¯è·¯å¾„å­˜åœ¨
    if not os.path.exists(clip_repo_path):
        logger.error(f"âŒ æµ‹è¯•ä»“åº“è·¯å¾„ä¸å­˜åœ¨: {clip_repo_path}")
        return False

    if not DEPENDENCIES_AVAILABLE:
        logger.error("âŒ ä¾èµ–ä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return False

    try:
        # æµ‹è¯• 1: ä½¿ç”¨ LocalFolderAnalysisFlow ç›´æ¥æµ‹è¯•ï¼ˆè·³è¿‡å‘é‡åŒ–ä»¥é¿å…ä¾èµ–é—®é¢˜ï¼‰
        logger.info("\n" + "="*60)
        logger.info("ğŸ§ª æµ‹è¯• 1: LocalFolderAnalysisFlow (è·³è¿‡å‘é‡åŒ–)")
        logger.info("="*60)

        flow = LocalFolderAnalysisFlow(use_vectorization=False, batch_size=3)
        shared_data = {"local_folder_path": clip_repo_path}

        await flow.run_async(shared_data)

        if shared_data.get("status") == "completed":
            logger.info("âœ… æµ‹è¯• 1 æˆåŠŸå®Œæˆ")
            logger.info(f"ï¿½ ç»“æœæ–‡ä»¶: {shared_data.get('result_filepath')}")
        else:
            logger.error("âŒ æµ‹è¯• 1 å¤±è´¥")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {shared_data.get('error', 'Unknown error')}")
            return False

        # æµ‹è¯• 2: ä½¿ç”¨ä¾¿æ·å‡½æ•° analyze_local_folder
        logger.info("\n" + "="*60)
        logger.info("ğŸ§ª æµ‹è¯• 2: analyze_local_folder ä¾¿æ·å‡½æ•°")
        logger.info("="*60)

        result_convenience = await analyze_local_folder(
            local_folder_path=clip_repo_path,
            use_vectorization=False,  # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œè·³è¿‡å‘é‡åŒ–
            batch_size=3
        )

        if result_convenience.get("status") == "completed":
            logger.info("âœ… æµ‹è¯• 2 æˆåŠŸå®Œæˆ")
            logger.info(f"ï¿½ ç»“æœæ–‡ä»¶: {result_convenience.get('result_filepath')}")
        else:
            logger.error("âŒ æµ‹è¯• 2 å¤±è´¥")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {result_convenience.get('error', 'Unknown error')}")
            return False

        # æµ‹è¯• 3: ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»ºæµç¨‹
        logger.info("\n" + "="*60)
        logger.info("ğŸ§ª æµ‹è¯• 3: create_analysis_flow å·¥å‚å‡½æ•°")
        logger.info("="*60)

        factory_flow = create_analysis_flow("local_quick", batch_size=3)
        shared_data_factory = {"local_folder_path": clip_repo_path}

        await factory_flow.run_async(shared_data_factory)

        if shared_data_factory.get("status") == "completed":
            logger.info("âœ… æµ‹è¯• 3 æˆåŠŸå®Œæˆ")
            logger.info(f"ï¿½ ç»“æœæ–‡ä»¶: {shared_data_factory.get('result_filepath')}")
        else:
            logger.error("âŒ æµ‹è¯• 3 å¤±è´¥")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {shared_data_factory.get('error', 'Unknown error')}")
            return False

        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        logger.info("="*60)

        return True

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
        return False


async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    logger.info("\n" + "="*60)
    logger.info("ğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†")
    logger.info("="*60)

    if not DEPENDENCIES_AVAILABLE:
        logger.error("âŒ ä¾èµ–ä¸å¯ç”¨ï¼Œè·³è¿‡é”™è¯¯å¤„ç†æµ‹è¯•")
        return False

    # æµ‹è¯•ä¸å­˜åœ¨çš„è·¯å¾„
    try:
        flow = LocalFolderAnalysisFlow(use_vectorization=False)
        shared_data = {"local_folder_path": "/nonexistent/path"}

        await flow.run_async(shared_data)

        if shared_data.get("status") == "failed":
            logger.info("âœ… é”™è¯¯å¤„ç†æµ‹è¯•æˆåŠŸ - æ­£ç¡®å¤„ç†äº†ä¸å­˜åœ¨çš„è·¯å¾„")
        else:
            logger.error("âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥ - åº”è¯¥è¿”å›å¤±è´¥çŠ¶æ€")
            return False

    except Exception as e:
        logger.info(f"âœ… é”™è¯¯å¤„ç†æµ‹è¯•æˆåŠŸ - æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {str(e)}")

    # æµ‹è¯•ç©ºè·¯å¾„
    try:
        flow = LocalFolderAnalysisFlow(use_vectorization=False)
        shared_data = {"local_folder_path": ""}

        await flow.run_async(shared_data)

        if shared_data.get("status") == "failed":
            logger.info("âœ… ç©ºè·¯å¾„é”™è¯¯å¤„ç†æµ‹è¯•æˆåŠŸ")
        else:
            logger.error("âŒ ç©ºè·¯å¾„é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥")
            return False

    except Exception as e:
        logger.info(f"âœ… ç©ºè·¯å¾„é”™è¯¯å¤„ç†æµ‹è¯•æˆåŠŸ - æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {str(e)}")

    return True


def progress_callback(completed: int, current_file: str):
    """è¿›åº¦å›è°ƒå‡½æ•°"""
    logger.info(f"ğŸ“Š è¿›åº¦æ›´æ–°: å·²å®Œæˆ {completed} ä¸ªæ–‡ä»¶ï¼Œå½“å‰å¤„ç†: {current_file}")


async def test_with_progress_callback():
    """æµ‹è¯•å¸¦è¿›åº¦å›è°ƒçš„åˆ†æ"""
    logger.info("\n" + "="*60)
    logger.info("ğŸ§ª æµ‹è¯•å¸¦è¿›åº¦å›è°ƒçš„åˆ†æ")
    logger.info("="*60)

    clip_repo_path = r"E:\Code\Agent1\Code-reader\data\repos\CLIP"

    if not DEPENDENCIES_AVAILABLE:
        logger.error("âŒ ä¾èµ–ä¸å¯ç”¨ï¼Œè·³è¿‡è¿›åº¦å›è°ƒæµ‹è¯•")
        return False

    try:
        result = await analyze_local_folder(
            local_folder_path=clip_repo_path,
            use_vectorization=False,  # å¿«é€Ÿæµ‹è¯•
            batch_size=2,
            progress_callback=progress_callback
        )

        if result.get("status") == "completed":
            logger.info("âœ… å¸¦è¿›åº¦å›è°ƒçš„æµ‹è¯•æˆåŠŸå®Œæˆ")
            return True
        else:
            logger.error("âŒ å¸¦è¿›åº¦å›è°ƒçš„æµ‹è¯•å¤±è´¥")
            return False

    except Exception as e:
        logger.error(f"âŒ å¸¦è¿›åº¦å›è°ƒçš„æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æœ¬åœ°æ–‡ä»¶å¤¹åˆ†ææµç¨‹æµ‹è¯•")

    # è¿è¡Œä¸»è¦æµ‹è¯•
    success1 = await test_local_folder_analysis()

    # è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•
    success2 = await test_error_handling()

    # è¿è¡Œè¿›åº¦å›è°ƒæµ‹è¯•
    success3 = await test_with_progress_callback()

    if success1 and success2 and success3:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½æˆåŠŸå®Œæˆï¼")
        return True
    else:
        logger.error("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(main())

    if success:
        print("\nâœ… æµ‹è¯•æˆåŠŸå®Œæˆ")
        sys.exit(0)
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")
        sys.exit(1)